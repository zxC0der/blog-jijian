---
draft: true
tags:
  - 数据库
  - 事务
  - 数据仓库
  - TODO
---

> 《数据密集型应用系统设计》第七章"事务"读后感以及结合最近入门大数据的一点笔记。

## **Database** vs. **Data Warehouse**

数据库主要用于**事务处理**，数据仓库主要用户**数据分析**。

数据库通常具有较复杂的表结构，满足范式要求，减少冗余数据，对读写进行优化，面向相对简单，少量数据的查询。

数据仓库通常是具有非规范化的表结构，冗余数据较多，只有读优化(大多数情况下，数据仓库不太会进行精确的写操作)，面向复杂，大量数据的查询。

可以理解为数据库是底层实际存储数据的地方，而数据仓库是在数据库的基础上，对数据重新进行整理，抽取出一层，方便进行数据分析。

举个例子:

> 作者：Mingqi
> 链接：https://www.zhihu.com/question/20623931/answer/750367153

通常情况，用户是通过API和数据库进行交互。

<img src="https://pic4.zhimg.com/50/v2-9eda0a203a1e39981e7c8659140a79a4_hd.jpg?source=1940ef5c" data-rawwidth="798" data-rawheight="237" data-size="normal" data-caption="" data-default-watermark-src="https://pic1.zhimg.com/50/v2-c05bb9ec7ea9f302530ab7d32f36982c_hd.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="798" data-original="https://pic2.zhimg.com/v2-9eda0a203a1e39981e7c8659140a79a4_r.jpg?source=1940ef5c"/>

如果要直接在数据库上做数据分析，数据监控等等任务的话，会存在以下问题:

- 数据分析通常涉及大量数据查询，可能会占用太多CPU从而影响系统的相应。
- 数据库的表结构通常比较复杂，需要数据分析人员有深入的了解。
- 数据库在进行大量数据查询的时候效率较低。
- 开放数据库的访问权限给数据分析人员，会有安全隐患。

为了解决以上四个问题，我们可以利用脚本，定期把数据库里面的所有数据Denormalize(使非规范化)到数据仓库里面，在数据仓库里面进行数据分析。

<img src="https://pic4.zhimg.com/50/v2-0f77b6b242155c802c528f50e63927f8_hd.jpg?source=1940ef5c" data-rawwidth="798" data-rawheight="204" data-size="normal" data-caption="" data-default-watermark-src="https://pic1.zhimg.com/50/v2-c84b7347cef653d81cb0745a2df264db_hd.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="798" data-original="https://pic2.zhimg.com/v2-0f77b6b242155c802c528f50e63927f8_r.jpg?source=1940ef5c"/>

如果有很多不同的组需要共享这个数据仓库，由于他们的脚本可能会相互影响。所以这里需要引入数据目录(Data Catalog)的概念来解决这个问题。

> A data catalog is a metadata management tool designed to help organizations find and manage large amounts of data – including tables, files and databases – stored in their ERP, human resources, finance and e-commerce systems as well as other sources like social media feeds. -  https://searchdatamanagement.techtarget.com/definition/data-catalog

我认为数据目录可以理解为就是存储一些元数据，用来管理这些不同组使用的数据仓库。抽象一点地理解，顾名思义就是每个组通过数据目录来找到对应的数据仓库。

<img src="https://pic2.zhimg.com/50/v2-4f4a92f54f9d478bce1152f995009cd6_hd.jpg?source=1940ef5c" data-rawwidth="1664" data-rawheight="802" data-size="normal" data-caption="" data-default-watermark-src="https://pic2.zhimg.com/50/v2-05280e6c729871350bfcc49b299328da_hd.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1664" data-original="https://pic4.zhimg.com/v2-4f4a92f54f9d478bce1152f995009cd6_r.jpg?source=1940ef5c"/>

这样的一个简单架构基本上是把做事务处理的数据库和做数据分析的数据仓库进行解耦，增加了整个系统的可扩展性。

再引用参考一个知乎回答，简洁地阐述了两者的主要区别:

> 作者：明说
> 链接：https://www.zhihu.com/question/20623931/answer/22191772

数据库和数据仓库其实都是通过某个软件，基于某种数据模型来组织和管理数据。但是，数据库通常更关注事务处理(OLTP)，而数据仓库更关注数据分析(OLAP)，因此对应的数据库模型上也会有很大的差异。数据库通常追求事务的效率，完整性，数据的一致性等等，主要遵从范式模型(1NF，2NF，3NF等等)，尽可能减少数据冗余；而数据仓库强调数据分析的效率，复杂查询的速度，数据之间的相关性分析等，所以在数据库模型上，数据仓库喜欢使用多维模型。

## Transaction

### ACID

事务具有/保证了数据的ACID四个特性。

- Atomicity: 事务的原子性和并发无关，而是描述同一个事务中多个操作要么全舍弃，要么全部完成并提交。如果没有原子性，在事务执行到一半时发生错误，将很难确定哪些操作已生效，哪些未生效，可以说原子性简化了这个问题。
- Consistency: 数据库在事务执行前后都处于一个正确的状态(比如转账场景中总钱数不变，比如满足数据库的约束)，实际上，通常来说一致性是应用层的属性，但是依赖数据库的原子性和隔离性来实现。
- Isolation: 多个事务之间会存在并发问题，隔离性保证并发的事务之间是相互隔离，互不影响的，实际上这个特性是对应了隔离级别里的可串行化，也就是事务并发执行的结果必须跟串行执行的结果完全一致。可串行化对数据库性能有极大的影响，因此在实际数据库实现中，大多数是采用了较弱的隔离级别。
- Durability: 持久性是一种不可能的保证，即一旦事务完成并提交，对数据库的影响就是永久的，即使发生了硬件故障或者数据库崩溃，写入的数据也不会丢失。

### Isolation Levels

#### Read Uncommitted

未提交读是最弱的隔离级别，只保证了已提交写(不会脏写(dirty writes))，**即可以读取另一个事务未提交的数据，但不能修改**。这已经是数据库系统的底线了。

#### Read Committed

已提交读，保证了只能读取到已提交事务的数据(不会脏读(dirty reads))，

已提交读是大多数数据库的默认隔离级别，如何实现?

脏写: 通常使用行锁来防止脏写，当一个事务想修改一个数据对象，必须先获得该对象的锁，一次只能有一个事务获得锁，其他事务需要等待。

脏读: 也可以使用行锁来实现，但是性能不好(对于大多数实现，实际上也有使用读锁的DB)，一个长时间的写入事务可能会导致多个只读事务陷入等待。大多数数据库采用读取旧版本值的方法(MVCC)来防止脏读。

#### Repeatable Read/Snapshot Isolation

简单来说，不可重复读(non-repeatable read)就是在一个事务中，两次读取到的数据都是其他事务成功提交的数据，但确是不匹配的。

快照隔离(可重复读)是这个问题的一个解决方案/隔离级别，即事务实际上只能看到某个特定时间点数据库快照的旧数据。

具体实现:

与已提交读类似，快照隔离也采用写锁来防止脏写，但读操作不采用任何锁，读写不相互阻塞。

读取采用了MVCC(multi-version concurrency control)，可以就是已提交读中防止脏读机制的一般化策略，数据库保留一个数据对象的多个版本(已提交读中只需要保留两个版本，因此MVCC也可以实现已提交读策略，典型的方法是已提交读是为每个查询创建一个快照，而快照隔离是对每个事务创建一个快照)，具体方法是通过给每个数据对象绑定上一个自增的事务id。

当一个事务要读取某个对象时，通过规则来判断对象快照的可见性。

![pic](https://vonng.gitbooks.io/ddia-cn/content/img/fig7-7.png)

参照上图，事务12第二次查询账户2时，只能查到上一个版本，也就是事务5的数据，而事务13的修改因为还没提交，所以还不可见。

即当以下两个条件都成立，则可见一个对象：

- 读**事务开始**时，创建该对象的事务已经提交。
- 对象未被标记为删除，或如果被**标记为删除**，请求删除的事务**在读事务开始时尚未提交**。

#### Lost Update

前面的已提交读和快照隔离主要保证了事务并发读写时，只读事务对数据的可见性，没有考虑两个事务并发写入的问题(后提交的会覆盖先提交的，导致丢失更新)。

- 原子写: 很多数据库提供了原子更新操作，可以避免丢失更新的问题。
- 显式锁定(悲观锁): 比如通过For Update关键字对查询对象显式加行锁。
- CAS(乐观锁): Compare And Swap，也是一种原子操作，只有当前值从上一次读取之后一直(ABA问题)没有变化，才允许更新。

以MySQL为例。

例子1:

- `SHOW VARIABLES LIKE 'transaction_isolation';`查看当前session默认隔离级别，默认为可重复读(SQL标准的可重复读其实也就是上文提到的快照隔离)。
- 此时数据表db.tab下有一条数据(id=1,num=2)。
- 通过`begin;`开启事务A。
- 通过`begin;`开启事务B。
- 事务A执行更新语句`UPDATE tab SET num=num-1 WHERE id=1;`，此时事务A可以查到最新数据，而事务B不能，因为事务A还没提交。
- 事务B执行更新语句`UPDATE tab SET num=num+1 WHERE id=1;`，此时事务B会卡住等待事务A的提交，这里其实跟可重复读无关，这是卡住是因为事务A获得了数据对象的锁，是为了解决脏写的问题(数据未提交，丢失更新是数据提交后还被覆盖)。
- 但是这种情况实际上才是丢失更新，但是在已提交读的隔离级别下也不会发生。

实际上，通常说的丢失更新是另一种逻辑意义上的丢失更新，如下。

例子2:

- 同例子1，有一条数据(id=1,num=2)。
- 通过`begin;`开启事务A。
- 通过`begin;`开启事务B。
- 事务A执行`SELECT * FROM tab WHERE id=1;`得到(id=1,num=2)**展示给用户**。
- 事务B执行`SELECT * FROM tab WHERE id=1;`得到(id=1,num=2)**展示给用户**。
- 事务A执行`UPDATE tab SET num=num-1 WHERE id=1;`并提交，数据修改为(id=1,num=1)。
- 事务B执行`UPDATE tab SET num=num+1 WHERE id=1;`并提交，数据修改为(id=1,num=2)。
- 事务B的更新被"覆盖"了，期望的num=3，却变成了2。但实际上这并不是真正的覆盖，因为事务B在执行更新之前，num的值已经被提交的事务A改为1了，只不过逻辑上事务B的用户看到的是之前查询的数据，因此造成错觉。

#### 写偏差

写入偏差也是另一种并发写入产生冲突的例子，不可重复读也叫读取偏差。

写入偏差可以看成是丢失更新的一种一般化情况，不同于丢失更新针对的是一个对象，写入偏差可以是针对多个对象的修改，可能导致数据库状态不一致或者不符合约束条件。

TODO 未完待续

### 2PL(two-phase locking)

两段锁，